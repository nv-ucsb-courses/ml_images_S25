{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "fa42eff7-e428-4e36-a5bd-08e099966daa",
      "cell_type": "markdown",
      "source": "### Simple MLP Learning with Backpropagation ",
      "metadata": {}
    },
    {
      "id": "d493dc99-c473-4348-9c50-a8975ec7e180",
      "cell_type": "code",
      "source": "import numpy as np\n\n# Forward propagation (no bias, no activation)\ndef forward_propagation(x,W1234,W56):\n\n    # Hidden layer\n    h12 = np.dot(x,W1234)\n\n    # Output layer\n    out = np.dot(h12,W56)\n\n    return h12, out",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 484
    },
    {
      "id": "aae2abbe-bf34-4001-a6cf-9cccbc9f0d13",
      "cell_type": "code",
      "source": "# Backward propagation\ndef backpropagation(actual,out,h12,W1234,W56,lr):\n\n    # Compute derivative of Loss wrt output (out)\n    delta = (out - actual)\n    \n    # Compute gradients for output layer\n    dW56 = delta * h12\n    \n    # Compute gradients for hidden layer\n    dW1234 = np.dot(delta * h12, W56.T)\n\n    # Update weights and biases\n    W1234 -= lr * dW1234\n    W56   -= lr * dW56\n\n    return W1234, W56",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 485
    },
    {
      "id": "4c60dbcd-9bb9-4908-938e-02a6bc8a26de",
      "cell_type": "code",
      "source": "def initialize_weights(test=False):\n    W1234 = np.random.rand(2,2)\n    W56   = np.random.rand(2)\n    \n    if test:\n        W1234[0,0] = .11\n        W1234[0,1] = .21\n        W1234[1,0] = .12\n        W1234[1,1] = .08\n        W56[0]     = .14\n        W56[1]     = .15\n    return W1234, W56",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 486
    },
    {
      "id": "fecd0542-061e-4456-af23-dec03bb1e554",
      "cell_type": "code",
      "source": "initialize_weights()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 485,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(array([[0.45913576, 0.98003258],\n        [0.49261809, 0.32875161]]),\n array([0.63340085, 0.24014562]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 487
    },
    {
      "id": "e573a9a7-45e4-49a2-8034-89c8384d455f",
      "cell_type": "code",
      "source": "# Training the network\ndef train_network(X, actuals,lr=0.1,epochs=1000,tol=1e-6,test=False,verbose=False):\n    \n    # Initialize weights and biases\n    W1234, W56 = initialize_weights(test)\n    if verbose: print (W1234,W56)\n    \n    # Training loop\n    for i in range(epochs):\n        total_loss = 0\n        \n        for x, actual in zip(X, actuals):\n            # Forward propagation\n            h12, out = forward_propagation(x, W1234, W56)\n        \n            # Backward propagation and update weights\n            W1234, W56 = backpropagation(actual,out,h12,W1234,W56,lr)\n\n            # Cumulative loss\n            total_loss += 0.5 * (out - actual)**2\n        \n        # Print loss (for monitoring)\n        if verbose: print(f\"Epoch {i+1}, Loss: {total_loss}\")\n\n        # Termination condition\n        if total_loss < tol:\n            print(f\"Converged at Epoch {i+1}, Loss: {total_loss[0]}\")\n            return W1234, W56\n\n    # All epochs used up\n    print(f\"All {i+1} Epochs used, Loss: {total_loss[0]}\")\n    \n    return W1234, W56",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 488
    },
    {
      "id": "dba3e0e1-7c7b-4a34-b1e6-94729c8b1d4f",
      "cell_type": "markdown",
      "source": "### Define training data and desired outcomes",
      "metadata": {}
    },
    {
      "id": "60877e98-4bad-4ea3-b97b-dc9510e685e7",
      "cell_type": "code",
      "source": "inputs = np.array([[2,3]])\nactual = np.array([[1]])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 497
    },
    {
      "id": "c1c698bf-3157-4a64-b6b3-80a7cba25bd9",
      "cell_type": "markdown",
      "source": "### Run Backpropagation-based learning learning",
      "metadata": {}
    },
    {
      "id": "41dbbf44-828c-47cb-935b-b84eb56f4cc1",
      "cell_type": "code",
      "source": "W1234, W56 = train_network(inputs,actual,epochs=10000,lr=0.02,tol=1e-10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Converged at Epoch 23, Loss: 6.14112560195096e-11\n"
        }
      ],
      "execution_count": 499
    },
    {
      "id": "eebed967-4ccd-494a-955f-c539b2cdaf7a",
      "cell_type": "markdown",
      "source": "### Test",
      "metadata": {}
    },
    {
      "id": "f7b205ed-dcf0-427b-8808-df3bf4fd9ab0",
      "cell_type": "code",
      "source": "# run forward path with refined weights\nfor x in inputs:\n    h12, out = forward_propagation(x, W1234, W56)\n        \n    # print results\n    print (x,round(out,3))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[2 3] 1.0\n"
        }
      ],
      "execution_count": 500
    },
    {
      "id": "62bb986f-8887-412b-a650-32c597fca74d",
      "cell_type": "code",
      "source": "# print model\nprint(W1234)\nprint(W56)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.05759021 0.2733899 ]\n [0.80271353 0.74477194]]\n[0.17596266 0.19992023]\n"
        }
      ],
      "execution_count": 501
    },
    {
      "id": "be169ee1-a913-4368-841a-d379b95d5a9d",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}